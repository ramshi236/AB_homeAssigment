{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autobrains HW\n",
    "# Intro:\n",
    "The notebook consists of two parts: infrastructure and usage example.\n",
    "\n",
    "# Disclaimer:\n",
    "\n",
    "the infrastructure part was short and easy, but the example part was challenging (and fun) because there wasn't any \"off-the-shelf\" vision model that easily exposes his intermediate layers outputs, so i had to reverse engineer the `torch.models.detection.fasterrcnn_resnet50_fpn`\n",
    "forward pass code and add new logic in the original pytorch implementation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infrastructure\n",
    "design for a creation of a subset dataset consistent of \"classification issue\" (as stated in the pdf)\n",
    "between multiple labels, along with model that can encapsulate logic (via `lightweight_function()`) that can \"solve\" the \"classification issue\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramshirazi/miniforge3/envs/abEnv0/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/ramshirazi/miniforge3/envs/abEnv0/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision.ops import box_iou\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.ops import boxes as box_ops, roi_align\n",
    "import pickle\n",
    "from typing import Optional, List, Callable\n",
    "\n",
    "from model_utils import CustomRCNN, label_map_model\n",
    "from data_utils import label_map_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaseDataset Class :\n",
    "- can receive a list of images targets and predications (target and predication are dicts)\n",
    "- can iteratively append elements, using `append()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        images: Optional[list[torch.Tensor]] = None,\n",
    "        targets: Optional[list[dict]] = None,\n",
    "        predictions: Optional[list[dict]] = None,\n",
    "    ):\n",
    "        self.images = images if images else []\n",
    "        self.targets = targets if targets else []\n",
    "        self.predictions = predictions if predictions else []\n",
    "\n",
    "    def append(\n",
    "        self,\n",
    "        image: torch.Tensor,\n",
    "        target: dict,\n",
    "        prediction: dict,\n",
    "    ):\n",
    "        self.images.append(image)\n",
    "        self.targets.append(target)\n",
    "        if prediction:\n",
    "            self.predictions.append(prediction)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_pkl(cls, root=\"./small_dataset.pkl\"):\n",
    "        dataset = cls()\n",
    "        with open(root, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        for image, target in data:\n",
    "            dataset.append(image, target, None)\n",
    "        return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model class:\n",
    "  responsible for enveloping a core model that returns the model predications along with a embedding vectors for each predication (the embeddings are the model intermediate layers outputs for each predication)\n",
    "  - the model can have a multiple bounding box predications for each images.\n",
    "  - the model outputs the embeddings for each bounding box predication \n",
    "  - can also \"solve\" a predication with a `lightweight_function()` callable, that operate on the model output and embeddings \n",
    "  - this model cant be trained \n",
    "  -  the model input is a list of RGB images (as a batch)\n",
    " #### NOTES: \n",
    " - we cant always stack the batched images to tensor (like shape : `(batch_dim,C,H,W)`) because the images size can vary, so we assume a list of images (tensors) as model input.\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNN:\n",
    "    def __init__(\n",
    "        self, model: torch.nn.Module, lightweight_function: Optional[Callable] = None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.lightweight_function = lightweight_function if lightweight_function else None\n",
    "\n",
    "    def inference(\n",
    "        self, input_data: list[torch.Tensor]\n",
    "    ) -> tuple[list[dict], list[torch.Tensor]]:\n",
    "        with torch.no_grad():\n",
    "            predictions, embedding_output = self.model(input_data)\n",
    "\n",
    "        if self.lightweight_function:\n",
    "            predictions = self.lightweight_function(predictions, embedding_output)\n",
    "\n",
    "        return predictions, embedding_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClassificationIssueDataset:\n",
    "inherent from `BaseDataset` with the additions of `self.embeddings` class member "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationIssueDataset(BaseDataset):\n",
    "    def __init__(\n",
    "        self, embeddings: list[list[torch.Tensor]] = None, *args, **kwargs\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.embeddings = embeddings if embeddings else []\n",
    "\n",
    "\n",
    "    def append(self, embeddings: list[torch.Tensor] = None, **kwargs):\n",
    "        super().append(**kwargs)\n",
    "        if embeddings is not None:\n",
    "            self.embeddings.append(embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_incorrect_pairs()\n",
    "this function encapsulate the logic for detecting a classification issue.\n",
    "\n",
    "if the pair of bounding boxes have iou > iou_threshold and the labels are not equal\n",
    "then the pair is incorrect.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incorrect_pairs(\n",
    "    bb_t: torch.Tensor,  # shape: (num_target_boxes, 4)\n",
    "    bb_p: torch.Tensor,  # shape: (num_predicted_boxes, 4)\n",
    "    labels_t: torch.Tensor,  # shape: (num_target_boxes)\n",
    "    labels_p: torch.Tensor,  # shape: (num_predicted_boxes)\n",
    "    iou_threshold=0.75,\n",
    "):\n",
    "    \"\"\"vectorized implementation using broadcasting\n",
    "    if the pair of bounding boxes have iou > iou_threshold and the labels are not equal\n",
    "    then the pair is incorrect\"\"\"\n",
    "    iou_matrix = box_iou(bb_t, bb_p)  # shape: (num_target_boxes, num_predicted_boxes)\n",
    "    incorrect_labels = torch.logical_not(\n",
    "        torch.eq(labels_t.unsqueeze(-1), labels_p.unsqueeze(-2))\n",
    "    )  # using broadcasting\n",
    "    incorrect_pairs = torch.nonzero(\n",
    "        torch.logical_and(iou_matrix > iou_threshold, incorrect_labels)\n",
    "    )\n",
    "    return incorrect_pairs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identify_classification_issue()\n",
    "- first, we are skipping images which dont have the labels in `labels`\n",
    "- we identify incorrect pairs (with the logic in `get_incorrect_pairs()`)\n",
    "- if the model predicted label is not in `labels`, we skip this sample.\n",
    "- we append to a `ClassificationIssueDataset` the relevant images, target, predications and embeddings.\n",
    "\n",
    "#### NOTES: \n",
    "- the function stops when the returned dataset has 3 elements (iterate through the whole dataset takes more then 5 minutes with my computer )\n",
    "- we could reduce the computation time by filtering the dataset for relevant images only and then run `model.inference(list_of_filtered_images)`, but my computer cant take it (along with creating a pytorch DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_classification_issue(\n",
    "    dataset: BaseDataset, model: BaseNN, labels: list[int], iou_threshold=0.75\n",
    ") -> ClassificationIssueDataset:\n",
    "    classification_issue_dataset = ClassificationIssueDataset()\n",
    "\n",
    "    for image, target in zip(dataset.images, dataset.targets):\n",
    "        if not any(l in target[\"labels\"] for l in labels):\n",
    "            continue\n",
    "        prediction, embeddings = model.inference([image])\n",
    "        prediction, embeddings = prediction[0], embeddings[0]\n",
    "\n",
    "        incorrect_pairs = get_incorrect_pairs(\n",
    "            bb_t=torch.stack(target[\"boxes\"]),\n",
    "            bb_p=prediction[\"boxes\"],\n",
    "            labels_t=torch.tensor(target[\"labels\"]),\n",
    "            labels_p=prediction[\"labels\"],\n",
    "            iou_threshold=iou_threshold,\n",
    "        )\n",
    "                \n",
    "        if len(incorrect_pairs) > 0:\n",
    "            prediction_labels = prediction[\"labels\"][incorrect_pairs[:, 1]]\n",
    "            \n",
    "            if not any(l in prediction_labels for l in labels):\n",
    "                continue\n",
    "            \n",
    "            classification_issue_dataset.append(\n",
    "                image=image,\n",
    "                target={\n",
    "                    \"labels\": torch.tensor(target[\"labels\"])[incorrect_pairs[:, 0]],\n",
    "                    \"boxes\": torch.stack(target[\"boxes\"])[incorrect_pairs[:, 0]],\n",
    "                },\n",
    "                prediction={\n",
    "                    \"labels\": prediction_labels,\n",
    "                    \"boxes\": prediction[\"boxes\"][incorrect_pairs[:, 1]],\n",
    "                },\n",
    "                embeddings=embeddings[incorrect_pairs[:, 1]],\n",
    "            )\n",
    "        if len(classification_issue_dataset.images) >= 3:\n",
    "            break\n",
    "    return classification_issue_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightweight_function()\n",
    "in order to \"solve\" the classification issue we can:\n",
    "- use KNN algorithm with the previously computed embedding vectors, this is the a good classic algorithm that benefits from a fast compute time, good accuracy for big datasets (which we have as stated in the goal2 of the pdf) and no training is required (just find the best K)\n",
    "- we can use SVM algorithm with the previously computed embedding vectors which can work great for high dimensional embedding vectors and very simple to implement.\n",
    "- we can train a new NN to create a new embedding (more like probability) space ,using contractive loss methods such as Prototypical Learning.\n",
    "### NOTE:\n",
    "because i already spent much time on this home assignment (and i can continue doing so for longer), i skipped the specific implementation for the `lightweight_function()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_classifier: # this is a dummy implementation\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "    def fit(self, X, y):\n",
    "        pass \n",
    "    def __call__(self, X):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, target, prediction):\n",
    "    \"\"\"visualize the image with the target and prediction boxes\"\"\"\n",
    "    image = Image.fromarray(image.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box in target[\"boxes\"]:\n",
    "        draw.rectangle(box.numpy(), outline=\"red\")\n",
    "    for box in prediction[\"boxes\"]:\n",
    "        draw.rectangle(box.numpy(), outline=\"green\")\n",
    "    image.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "first we use my `CustomRCNN` class as the \"of-the-shelf\" `CORE_MODEL`.\n",
    "\n",
    "the `raw_model.roi_heads.box_head.fc7` layer, is the final embedding layer for the proposed regions.\n",
    "\n",
    "then we can envelope `CORE_MODEL` with our `BaseNN` class.\n",
    "\n",
    "then we load our pickle `small_dataset` (which was previously generated using `data_utils.py` module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramshirazi/miniforge3/envs/abEnv0/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ramshirazi/miniforge3/envs/abEnv0/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "raw_model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "CORE_MODEL = CustomRCNN(\n",
    "    model=raw_model,\n",
    "    embedding_layer_name=\"fc7\",\n",
    "    embedding_layer=raw_model.roi_heads.box_head.fc7,\n",
    ")\n",
    "base_model = BaseNN(CORE_MODEL)\n",
    "base_dataset = BaseDataset.load_from_pkl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth label: motorcycle, Predicted label: bicycle\n"
     ]
    }
   ],
   "source": [
    "classification_issue_dataset = identify_classification_issue(\n",
    "    base_dataset, base_model, labels=[2, 4]\n",
    ")\n",
    "gt_label_name = label_map_dataset[int(classification_issue_dataset.targets[0][\"labels\"])]\n",
    "pred_label_name = label_map_model[int(classification_issue_dataset.predictions[0][\"labels\"])]\n",
    "\n",
    "visualize(\n",
    "    classification_issue_dataset.images[0],\n",
    "    classification_issue_dataset.targets[0],\n",
    "    classification_issue_dataset.predictions[0],\n",
    ")\n",
    "print(f\"Ground truth label: {gt_label_name}, Predicted label: {pred_label_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth label: bicycle, Predicted label: motorcycle\n"
     ]
    }
   ],
   "source": [
    "gt_label_name = label_map_dataset[int(classification_issue_dataset.targets[1][\"labels\"])]\n",
    "pred_label_name = label_map_model[int(classification_issue_dataset.predictions[1][\"labels\"])]\n",
    "\n",
    "visualize(\n",
    "    classification_issue_dataset.images[1],\n",
    "    classification_issue_dataset.targets[1],\n",
    "    classification_issue_dataset.predictions[1],\n",
    ")\n",
    "print(f\"Ground truth label: {gt_label_name}, Predicted label: {pred_label_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth label: motorcycle, Predicted label: bicycle\n"
     ]
    }
   ],
   "source": [
    "gt_label_name = label_map_dataset[int(classification_issue_dataset.targets[2][\"labels\"])]\n",
    "pred_label_name = label_map_model[int(classification_issue_dataset.predictions[2][\"labels\"])]\n",
    "\n",
    "visualize(\n",
    "    classification_issue_dataset.images[2],\n",
    "    classification_issue_dataset.targets[2],\n",
    "    classification_issue_dataset.predictions[2],\n",
    ")\n",
    "print(f\"Ground truth label: {gt_label_name}, Predicted label: {pred_label_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wdEnv0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
